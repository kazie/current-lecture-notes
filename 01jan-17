Generic structure of parallel computers
	A perallel computer is a collection of concurrently executing, communicating processing elements
	Potential for largeperformance boost:
		  1000 processors run 1000 times faster than one processor
	Or, tackle a problem 1000 time the size, accuracy, ...
	A parallel computer increases memory capacity &c

	A collection of P processor--memory paries that communicates with eachother

	When there is a global memory we have a shared memory architecture, also known as a multiprocessor
	Where there is no global memory we have a "share nothing" architecture (also known as a distributed
	memory architecture), also known as a multicomputer.

	Ferlin is both multiprocessor and multicomputer, because it is a cluster of multicored computers.
	Each processor as a cache and each computer has a shared memory, the among is cache is a trade off.
	For each computer the memory is treated as with shared memory only.



A first example: rank sort:

  	Problem: Given n (pairwise distinct) numbers. Sort the numbers in increasing order.
	
	
	Solution:
	
	Let the rank r_i of an element a_i of the set M of numbers be the number
	of elements being less then that element,

	   r_i = #{a_j :in: M | a_j < a_i}
	
	In a fully sorted list, the position of element i is just it rank r_i.

	   C:
		for (i = 0; i q n; i++)
		    {
			r[i] = 0;
			for (j = 0; j < n; j++)
			    if (a[j] < a[i])
			         r[i]++;
		    }

	   FORTRAN-version available in slides.

